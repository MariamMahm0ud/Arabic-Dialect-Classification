{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_pTdi2fiyHN"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RFuLgxa--i8W"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install nltk\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ubZjS5RwgRBG"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "!pip install emoji"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YUV4ftnFTuJp"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import spacy\n",
        "import nltk\n",
        "import string\n",
        "from nltk.tokenize import word_tokenize\n",
        "import re\n",
        "import gensim\n",
        "import matplotlib.pyplot as plt\n",
        "# import pyarabic.araby as araby\n",
        "import sqlite3\n",
        "import emoji\n",
        "#import stanza\n",
        "#import camel_tools as ct\n",
        "from nltk.corpus import stopwords\n",
        "pd.set_option('display.max_rows', 500)\n",
        "pd.set_option('display.max_colwidth', 500)\n",
        "# from tnkeeh import Tnkeeh\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, SpatialDropout1D, Dropout\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.layers import Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DWZ-l7mJmf6G"
      },
      "outputs": [],
      "source": [
        "import sqlite3\n",
        "import pandas as pd\n",
        "import re\n",
        "import emoji\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CzuPhKb_-F9Q"
      },
      "outputs": [],
      "source": [
        "X_train_path = 'X_train.csv'\n",
        "X_test_path = 'X_test.csv'\n",
        "y_train_path = 'y_train.csv'\n",
        "y_test_path = 'y_test.csv'\n",
        "\n",
        "X_train = pd.read_csv(X_train_path,encoding='utf-8')\n",
        "X_test = pd.read_csv(X_test_path,encoding='utf-8')\n",
        "y_train = pd.read_csv(y_train_path,encoding='utf-8')\n",
        "y_test = pd.read_csv(y_test_path,encoding='utf-8')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing\n"
      ],
      "metadata": {
        "id": "gccirx5rqEal"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "hlPLztBomAfS"
      },
      "outputs": [],
      "source": [
        "y_train = y_train.values.ravel()\n",
        "y_test = y_test.values.ravel()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dV79_Vx0RMTK"
      },
      "outputs": [],
      "source": [
        "# Handle NaN values in text columns by dropping them along with corresponding labels\n",
        "X_train = X_train.dropna(subset=['text'])\n",
        "X_test = X_test.dropna(subset=['text'])\n",
        "y_train = y_train[X_train.index]\n",
        "y_test = y_test[X_test.index]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## class weight computation\n",
        "\n",
        "This function computes class weights based on the balanced class distribution in the training data.\n",
        "\n",
        "### Parameters:\n",
        "- `classes`: numpy array containing all unique class labels in both training and testing data.\n",
        "- `y_train`: numpy array containing class labels for the training data.\n",
        "- `y_test`: numpy array containing class labels for the testing data.\n",
        "\n",
        "### Returns:\n",
        "- `class_weight_dict`: dictionary containing class weights computed based on the balanced class distribution.\n"
      ],
      "metadata": {
        "id": "n_0eilo1rcNC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classes = np.unique(np.concatenate((y_train, y_test)))\n",
        "class_weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train)\n",
        "class_weight_dict = {cls: weight for cls, weight in zip(classes, class_weights)}"
      ],
      "metadata": {
        "id": "kkpKFalvqnMp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Logistic Regression with TF-IDF Vectorization\n",
        "1. **Vectorize Text Data using TF-IDF:**\n",
        "   - Create a TF-IDF vectorizer.\n",
        "   - Fit the vectorizer on the training text data (`X_train['text']`) to learn the vocabulary and compute IDF values.\n",
        "   - Transform both the training and testing text data into TF-IDF features.\n",
        "\n",
        "2. **Train Logistic Regression Model with Class Weights:**\n",
        "   - Instantiate a Logistic Regression model with specified class weights (`class_weight_dict`) to handle class imbalance.\n",
        "   - Fit the Logistic Regression model on the TF-IDF features of the training data.\n",
        "\n",
        "3. **Predict on the Test Set:**\n",
        "   - Use the trained Logistic Regression model to predict labels for the TF-IDF features of the testing data (`X_test_tfidf`).\n",
        "\n",
        "4. **Calculate Accuracy:**\n",
        "   - Compute the accuracy score of the Logistic Regression model on the test set to evaluate its performance.\n",
        "\n",
        "### Parameters:\n",
        "- `X_train['text']`: Training text data containing sentences/documents.\n",
        "- `X_test['text']`: Testing text data containing sentences/documents.\n",
        "- `y_train`: Labels corresponding to the training text data.\n",
        "- `y_test`: Labels corresponding to the testing text data.\n",
        "- `class_weight_dict`: Dictionary containing class weights for balancing class distribution.\n",
        "\n",
        "### Returns:\n",
        "- `accuracy_tfidf`: Accuracy score of the Logistic Regression model on the test set.\n",
        "\n"
      ],
      "metadata": {
        "id": "FPGuweo3wgYT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorize text data using TF-IDF\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train['text'])\n",
        "X_test_tfidf = vectorizer.transform(X_test['text'])"
      ],
      "metadata": {
        "id": "fA0mnxywqdbA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQ4yTFEreZwJ",
        "outputId": "08c2fde5-a877-441f-b21d-43043eb75d0f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train_tfidf shape: (117972, 179933)\n",
            "X_test_tfidf shape: (29482, 179933)\n",
            "y_train shape: (117972,)\n",
            "y_test shape: (29482,)\n",
            "Test Accuracy with TF-IDF and Logistic Regression: 0.8016\n"
          ]
        }
      ],
      "source": [
        "print(\"X_train_tfidf shape:\", X_train_tfidf.shape)\n",
        "print(\"X_test_tfidf shape:\", X_test_tfidf.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"y_test shape:\", y_test.shape)\n",
        "\n",
        "# Train the Logistic Regression model with class weights\n",
        "lr_model_tfidf = LogisticRegression(class_weight=class_weight_dict, max_iter=1000)\n",
        "lr_model_tfidf.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "lr_labels_tfidf = lr_model_tfidf.predict(X_test_tfidf)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy_tfidf = accuracy_score(y_test, lr_labels_tfidf)\n",
        "print(f'Test Accuracy with TF-IDF and Logistic Regression: {accuracy_tfidf:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LxBF_HEsorxh",
        "outputId": "c05b5c9b-9e62-47f3-ca02-0d3852af04fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Macro F1-score: 0.7696901140061857\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "macro_f1 = f1_score(y_test, lr_labels_tfidf, average='macro')\n",
        "print(\"Macro F1-score:\", macro_f1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oP20A0JZz-mS",
        "outputId": "ebd9abb6-48b5-42c3-ea9d-5016f09f931a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8016\n"
          ]
        }
      ],
      "source": [
        "accuracy = accuracy_score(y_test, lr_labels_tfidf)\n",
        "print(f'Accuracy: {accuracy:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLhHWW7j58Fm",
        "outputId": "5f5a3c61-0a5e-4769-b989-0a7e718e7147"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          EG       0.89      0.82      0.85     11459\n",
            "          LB       0.82      0.83      0.83      5570\n",
            "          LY       0.78      0.80      0.79      7256\n",
            "          MA       0.69      0.74      0.71      2276\n",
            "          SD       0.63      0.71      0.67      2921\n",
            "\n",
            "    accuracy                           0.80     29482\n",
            "   macro avg       0.76      0.78      0.77     29482\n",
            "weighted avg       0.81      0.80      0.80     29482\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_test, lr_labels_tfidf))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "buzwlMD_6MFK",
        "outputId": "2d79e789-9eae-4475-de0c-1976b865fd74"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['lr_pipeline_tfidf.joblib']"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import joblib\n",
        "joblib.dump(lr_model_tfidf, 'lr_pipeline_tfidf.joblib')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Logistic Regression with CountVectorizer\n",
        "1. **Vectorize Text Data using CountVectorizer:**\n",
        "   - Create a CountVectorizer object.\n",
        "   - Fit the vectorizer on the training text data (`X_train['text']`) to learn the vocabulary.\n",
        "   - Transform both the training and testing text data into count-based features.\n",
        "\n",
        "2. **Train Logistic Regression Model with Class Weights:**\n",
        "   - Instantiate a Logistic Regression model with specified class weights (`class_weight_dict`) to handle class imbalance.\n",
        "   - Fit the Logistic Regression model on the count-based features of the training data.\n",
        "\n",
        "3. **Predict on the Test Set:**\n",
        "   - Use the trained Logistic Regression model to predict labels for the count-based features of the testing data (`X_test_count`).\n",
        "\n",
        "4. **Calculate Accuracy:**\n",
        "   - Compute the accuracy score of the Logistic Regression model on the test set to evaluate its performance.\n",
        "\n",
        "### Parameters:\n",
        "- `X_train['text']`: Training text data containing sentences/documents.\n",
        "- `X_test['text']`: Testing text data containing sentences/documents.\n",
        "- `y_train`: Labels corresponding to the training text data.\n",
        "- `y_test`: Labels corresponding to the testing text data.\n",
        "- `class_weight_dict`: Dictionary containing class weights for balancing class distribution.\n",
        "\n",
        "### Returns:\n",
        "- `accuracy_count`: Accuracy score of the Logistic Regression model on the test set.\n",
        "\n"
      ],
      "metadata": {
        "id": "8DquuEJbynr_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Ileg4GKjf2XH",
        "outputId": "bd902e69-b993-44b3-af79-bc30c2de5ada"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy with CountVectorizer and Logistic Regression: 0.8011\n"
          ]
        }
      ],
      "source": [
        "# Vectorize text data using CountVectorizer\n",
        "vectorizer = CountVectorizer()\n",
        "X_train_count = vectorizer.fit_transform(X_train['text'])\n",
        "X_test_count = vectorizer.transform(X_test['text'])\n",
        "\n",
        "# Train the Logistic Regression model with class weights\n",
        "lr_model_count = LogisticRegression(class_weight=class_weight_dict, max_iter=1000)\n",
        "lr_model_count.fit(X_train_count, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "lr_labels_count = lr_model_count.predict(X_test_count)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy_count = accuracy_score(y_test, lr_labels_count)\n",
        "print(f'Test Accuracy with CountVectorizer and Logistic Regression: {accuracy_count:.4f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7XtuuxF46h4",
        "outputId": "05bbe4dc-24a5-4fce-9baf-b9c775b7cb90"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Macro F1-score: 0.7666504122916823\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "macro_f1 = f1_score(y_test, lr_labels_count, average='macro')\n",
        "print(\"Macro F1-score:\", macro_f1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VU_axSxg46h5",
        "outputId": "013508a0-37fe-45bf-bd0d-9259a05dd95b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8011\n"
          ]
        }
      ],
      "source": [
        "accuracy = accuracy_score(y_test, lr_labels_count)\n",
        "print(f'Accuracy: {accuracy:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBQVV88R53ts",
        "outputId": "52bb696d-6f5e-4ef8-80f6-dbaee894349b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          EG       0.88      0.83      0.85     11459\n",
            "          LB       0.81      0.84      0.82      5570\n",
            "          LY       0.78      0.80      0.79      7256\n",
            "          MA       0.70      0.71      0.71      2276\n",
            "          SD       0.64      0.68      0.66      2921\n",
            "\n",
            "    accuracy                           0.80     29482\n",
            "   macro avg       0.76      0.77      0.77     29482\n",
            "weighted avg       0.80      0.80      0.80     29482\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_test, lr_labels_count))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z49JYDv96WQn",
        "outputId": "b1cd1727-a906-41a7-a40f-cde3afba12d3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['lr_pipeline_count.joblib']"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "joblib.dump(lr_model_count, 'lr_pipeline_count.joblib')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multinomial Naive Bayes with TF-IDF Vectorization\n",
        "1. **Compute Class Weights:**\n",
        "   - Calculate class weights using `compute_class_weight` based on the distribution of classes in the training data.\n",
        "\n",
        "2. **Set Class Priors:**\n",
        "   - Normalize the class weights to get class priors by dividing each class weight by the sum of all class weights.\n",
        "\n",
        "3. **Instantiate Multinomial Naive Bayes Model:**\n",
        "   - Create a Multinomial Naive Bayes model (`nb_model_tfidf`) with class priors set to the normalized class weights.\n",
        "\n",
        "4. **Fit the Model:**\n",
        "   - Train the Multinomial Naive Bayes model on the TF-IDF vectorized training data (`X_train_tfidf`) and corresponding labels (`y_train`).\n",
        "\n",
        "5. **Predict on the Test Set:**\n",
        "   - Use the trained model to predict labels for the TF-IDF vectorized testing data (`X_test_tfidf`).\n",
        "\n",
        "### Parameters:\n",
        "- `X_train_tfidf`: TF-IDF vectorized training data.\n",
        "- `X_test_tfidf`: TF-IDF vectorized testing data.\n",
        "- `y_train`: Labels corresponding to the training data.\n",
        "- `class_weights`: Class weights computed using `compute_class_weight`.\n",
        "- `class_prior`: Class priors normalized from class weights.\n",
        "\n",
        "### Returns:\n",
        "- `nb_labels_tfidf`: Predicted labels for the TF-IDF vectorized testing data.\n"
      ],
      "metadata": {
        "id": "g5skBfymzfLw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DihleuYe5ARj"
      },
      "outputs": [],
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "class_prior = class_weights / class_weights.sum()\n",
        "nb_model_tfidf = MultinomialNB(class_prior=class_prior)\n",
        "\n",
        "nb_model_tfidf.fit(X_train_tfidf, y_train)\n",
        "nb_labels_tfidf = nb_model_tfidf.predict(X_test_tfidf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2QgvB8b5ARk",
        "outputId": "ec0fcefe-ec20-4d37-ded2-e7ff1b3a4ec5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Macro F1-score: 0.7406963220528369\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "nb_macro_f1_tfidf = f1_score(y_test, nb_labels_tfidf, average='macro')\n",
        "print(\"Macro F1-score:\", nb_macro_f1_tfidf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wivtv7cJ5ARk",
        "outputId": "80bb62a8-7f64-42cf-eaff-3fbcd2f17c6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.7835\n"
          ]
        }
      ],
      "source": [
        "nb_accuracy_tfidf = accuracy_score(y_test, nb_labels_tfidf)\n",
        "print(f'Accuracy: {nb_accuracy_tfidf:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vIBFOmdq5zvz",
        "outputId": "f4c4d475-2ade-4bc7-b20a-31b84be1a46c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          EG       0.88      0.83      0.85     11459\n",
            "          LB       0.86      0.83      0.84      5570\n",
            "          LY       0.89      0.70      0.79      7256\n",
            "          MA       0.50      0.79      0.61      2276\n",
            "          SD       0.53      0.72      0.61      2921\n",
            "\n",
            "    accuracy                           0.78     29482\n",
            "   macro avg       0.73      0.77      0.74     29482\n",
            "weighted avg       0.81      0.78      0.79     29482\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_test, nb_labels_tfidf))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1xKPuij7ds6",
        "outputId": "ae6320bb-9e1a-4c2b-a10d-619e1e75a66b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['nb_pipeline_tfidf.joblib']"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "joblib.dump(nb_model_tfidf, 'nb_pipeline_tfidf.joblib')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multinomial Naive Bayes with CountVectorizer\n",
        "\n",
        "1. **Compute Class Weights:**\n",
        "   - Calculate class weights using `compute_class_weight` based on the distribution of classes in the training data.\n",
        "\n",
        "2. **Set Class Priors:**\n",
        "   - Normalize the class weights to get class priors by dividing each class weight by the sum of all class weights.\n",
        "\n",
        "3. **Instantiate Multinomial Naive Bayes Model:**\n",
        "   - Create a Multinomial Naive Bayes model (`nb_model_count`) with class priors set to the normalized class weights.\n",
        "\n",
        "4. **Fit the Model:**\n",
        "   - Train the Multinomial Naive Bayes model on the CountVectorizer vectorized training data (`X_train_count`) and corresponding labels (`y_train`).\n",
        "\n",
        "5. **Predict on the Test Set:**\n",
        "   - Use the trained model to predict labels for the CountVectorizer vectorized testing data (`X_test_count`).\n",
        "\n",
        "### Parameters:\n",
        "- `X_train_count`: CountVectorizer vectorized training data.\n",
        "- `X_test_count`: CountVectorizer vectorized testing data.\n",
        "- `y_train`: Labels corresponding to the training data.\n",
        "- `class_weights`: Class weights computed using `compute_class_weight`.\n",
        "- `class_prior`: Class priors normalized from class weights.\n",
        "\n",
        "### Returns:\n",
        "- `nb_labels_count`: Predicted labels for the CountVectorizer vectorized testing data.\n"
      ],
      "metadata": {
        "id": "2x8fjHAb0ERZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "ZUMyX0w20Glv"
      },
      "outputs": [],
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "\n",
        "class_prior = class_weights / class_weights.sum()\n",
        "nb_model_count = MultinomialNB(class_prior=class_prior)\n",
        "\n",
        "\n",
        "nb_model_count.fit(X_train_count, y_train)\n",
        "nb_labels_count = nb_model_count.predict(X_test_count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1IN6VsW0Glw",
        "outputId": "4096eb75-f83d-44cf-e904-87974c771c2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Macro F1-score: 0.7849156085676153\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "nb_macro_f1 = f1_score(y_test, nb_labels_count, average='macro')\n",
        "print(\"Macro F1-score:\", nb_macro_f1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWb-_B-40Glx",
        "outputId": "5b65ce67-7598-4ffe-c80d-59c8153fc6aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8242\n"
          ]
        }
      ],
      "source": [
        "nb_accuracy = accuracy_score(y_test, nb_labels_count)\n",
        "print(f'Accuracy: {nb_accuracy:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPfRlWzR5eQw",
        "outputId": "e177eb6b-f8c5-4941-a7c3-757c953c8d0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          EG       0.86      0.90      0.88     11459\n",
            "          LB       0.86      0.85      0.86      5570\n",
            "          LY       0.85      0.78      0.81      7256\n",
            "          MA       0.70      0.72      0.71      2276\n",
            "          SD       0.66      0.67      0.67      2921\n",
            "\n",
            "    accuracy                           0.82     29482\n",
            "   macro avg       0.79      0.78      0.78     29482\n",
            "weighted avg       0.82      0.82      0.82     29482\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_test, nb_labels_count))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0iAWE0WA7pzd",
        "outputId": "86e2ee2a-d6c3-4e29-9d37-2035500b6a12"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['nb_pipeline_count.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "joblib.dump(nb_model_count, 'nb_pipeline_count.joblib')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing the model\n"
      ],
      "metadata": {
        "id": "Rm6WyhJJ0Wtp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = joblib.load('nb_pipeline_count.joblib')  # Load the model using joblib\n"
      ],
      "metadata": {
        "id": "j-SxqO2KedHb"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Define the new sentence\n",
        "new_sentence = \"مبروك العواشر وتعيد وتعاود:\"\n",
        "\n",
        "# Preprocess the new sentence using the same vectorizer used for training\n",
        "new_sentence_vec = vectorizer.transform([new_sentence])\n",
        "\n",
        "# Predict the label for the new sentence using the trained logistic regression model\n",
        "predicted_label = model.predict(new_sentence_vec)\n",
        "\n",
        "print(\"Predicted label:\", predicted_label)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMwmkLJtaRmd",
        "outputId": "1ef521b2-4849-49be-bb94-c9b0e5fbfbb3"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted label: ['MA']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CA_VAOwbwXv0"
      },
      "source": [
        "# deep learning\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "1. **Label Encoding:**\n",
        "   - Encode the target variable (`y_train` and `y_test`) using `LabelEncoder`.\n",
        "   - Transform the original class labels into numerical values.\n",
        "\n",
        "2. **One-Hot Encoding (Optional):**\n",
        "   - Convert the encoded labels into categorical one-hot encoded format using `to_categorical` if needed.\n",
        "\n",
        "3. **Compute Class Weights:**\n",
        "   - Calculate class weights using `compute_class_weight` to handle imbalanced class distributions.\n",
        "   - Pass the encoded class labels (`y_train_encoded`) to compute class weights.\n",
        "\n",
        "### Parameters:\n",
        "- `y_train`: Target variable (labels) for the training data.\n",
        "- `y_test`: Target variable (labels) for the testing data.\n",
        "- `label_encoder`: Instance of the `LabelEncoder` class used for label encoding.\n",
        "- `y_train_encoded`: Encoded labels for the training data.\n",
        "- `y_test_encoded`: Encoded labels for the testing data.\n",
        "- `y_train_categorical`: One-hot encoded labels for the training data (if applicable).\n",
        "- `y_test_categorical`: One-hot encoded labels for the testing data (if applicable).\n",
        "- `class_weight_dict`: Dictionary containing the computed class weights.\n",
        "\n",
        "### Returns:\n",
        "- `class_weight_dict`: Dictionary containing class weights for each class.\n",
        "\n"
      ],
      "metadata": {
        "id": "dFnVNhW_1XM9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YqwGsxY_vJoY"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, LSTM, Bidirectional, Dense, Dropout, GRU, SimpleRNN\n",
        "from keras.optimizers import Adam\n",
        "from tensorflow.keras.regularizers import l2, l1\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "y_test_encoded = label_encoder.transform(y_test)\n",
        "\n",
        "\n",
        "y_train_categorical = to_categorical(y_train_encoded)\n",
        "y_test_categorical = to_categorical(y_test_encoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uf4Aoz9N1IyV",
        "outputId": "f88db764-cc55-4716-efce-c82b9a5c111f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class weights: {0: 0.5120645875382512, 1: 1.0716933139534883, 2: 0.8083595998355488, 3: 2.5540593201991775, 4: 2.0601065223085655}\n"
          ]
        }
      ],
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(y_train_encoded), y=y_train_encoded)\n",
        "class_weight_dict = dict(enumerate(class_weights))\n",
        "print(\"Class weights:\", class_weight_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenization and Padding\n",
        "\n",
        "The provided code initializes a Tokenizer object to tokenize the text data and pad sequences to ensure uniform length for modeling.\n",
        "\n",
        "- `MAX_NB_WORDS`: Maximum number of unique words to tokenize (set to 50,000).\n",
        "- `MAX_SEQUENCE_LENGTH`: Maximum length of sequences after padding (set to 60).\n",
        "\n",
        "## Model Architecture\n",
        "\n",
        "The defined model architecture is a recurrent neural network (RNN) with an embedding layer, spatial dropout, LSTM layer, and dense layer.\n",
        "\n",
        "- Embedding Layer: Maps the tokenized words to dense vectors of fixed size (100-dimensional).\n",
        "- Spatial Dropout: Applies dropout along the spatial dimensions to prevent overfitting (dropout rate set to 0.5).\n",
        "- LSTM Layer: Long Short-Term Memory layer with 50 units and dropout of 0.5 for input and recurrent connections.\n",
        "- Dense Layer: Output layer with softmax activation function for multiclass classification.\n",
        "\n",
        "## Model Compilation and Training\n",
        "\n",
        "The model is compiled using categorical cross-entropy loss and the Adam optimizer.\n",
        "\n",
        "- Early Stopping: Stops training if the validation loss does not improve for 3 epochs to prevent overfitting.\n",
        "\n",
        "## Training Process\n",
        "\n",
        "The model is trained on the padded sequences of the training data with class weights to handle class imbalance.\n",
        "\n",
        "- Training occurs over 10 epochs with a batch size of 300 and a validation split of 0.2.\n",
        "\n",
        "## Model Evaluation\n",
        "\n",
        "The trained model is evaluated on the test set, and the test accuracy is printed.\n"
      ],
      "metadata": {
        "id": "Na07j-NV573a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKW9CKS6hTDQ",
        "outputId": "b6b0a8b6-3b25-4d45-fd0d-8cc5b1b26553"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, 60, 100)           5000000   \n",
            "                                                                 \n",
            " spatial_dropout1d_2 (Spati  (None, 60, 100)           0         \n",
            " alDropout1D)                                                    \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 50)                30200     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 5)                 255       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5030455 (19.19 MB)\n",
            "Trainable params: 5030455 (19.19 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n",
            "315/315 [==============================] - 101s 310ms/step - loss: 1.1157 - accuracy: 0.5719 - val_loss: 0.6779 - val_accuracy: 0.7646\n",
            "Epoch 2/10\n",
            "315/315 [==============================] - 80s 254ms/step - loss: 0.6335 - accuracy: 0.7807 - val_loss: 0.5753 - val_accuracy: 0.8019\n",
            "Epoch 3/10\n",
            "315/315 [==============================] - 74s 234ms/step - loss: 0.4903 - accuracy: 0.8322 - val_loss: 0.5553 - val_accuracy: 0.8039\n",
            "Epoch 4/10\n",
            "315/315 [==============================] - 71s 224ms/step - loss: 0.4068 - accuracy: 0.8605 - val_loss: 0.5650 - val_accuracy: 0.8070\n",
            "Epoch 5/10\n",
            "315/315 [==============================] - 69s 218ms/step - loss: 0.3479 - accuracy: 0.8798 - val_loss: 0.5899 - val_accuracy: 0.7999\n",
            "Epoch 6/10\n",
            "315/315 [==============================] - 69s 221ms/step - loss: 0.3054 - accuracy: 0.8934 - val_loss: 0.6006 - val_accuracy: 0.8034\n",
            "922/922 [==============================] - 19s 21ms/step - loss: 0.5585 - accuracy: 0.8016\n",
            "Test Accuracy: 0.8016\n"
          ]
        }
      ],
      "source": [
        "# Tokenizer initialization\n",
        "MAX_NB_WORDS = 50000\n",
        "MAX_SEQUENCE_LENGTH = 60\n",
        "tokenizer = Tokenizer(num_words=MAX_NB_WORDS, lower=True)\n",
        "tokenizer.fit_on_texts(X_train['text'])\n",
        "\n",
        "# Convert texts to sequences\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train['text'])\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test['text'])\n",
        "\n",
        "# Pad sequences to the same length\n",
        "X_train_pad = pad_sequences(X_train_seq, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "X_test_pad = pad_sequences(X_test_seq, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "\n",
        "# Encode the labels as one-hot vectors\n",
        "y_train_categorical = to_categorical([classes.tolist().index(label) for label in y_train], num_classes=len(classes))\n",
        "y_test_categorical = to_categorical([classes.tolist().index(label) for label in y_test], num_classes=len(classes))\n",
        "\n",
        "# Define the model with reduced complexity and increased dropout\n",
        "model = Sequential()\n",
        "model.add(Embedding(MAX_NB_WORDS, 100, input_length=MAX_SEQUENCE_LENGTH))  # Embedding dimension\n",
        "model.add(SpatialDropout1D(0.5))  # Increased dropout rate\n",
        "model.add(LSTM(50, dropout=0.5, recurrent_dropout=0.5))  # LSTM units with dropout\n",
        "model.add(Dense(len(classes), activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "# Define early stopping\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "# Train the model with class weights\n",
        "history = model.fit(X_train_pad, y_train_categorical, epochs=10, batch_size=300, validation_split=0.2, callbacks=[early_stop], class_weight=class_weight_dict)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "loss, accuracy = model.evaluate(X_test_pad, y_test_categorical)\n",
        "print(f'Test Accuracy: {accuracy:.4f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Confusion Matrix and Classification Report\n",
        "\n",
        "This code snippet demonstrates the generation of a confusion matrix and a classification report to evaluate the performance of a classification model.\n",
        "\n",
        "### Steps:\n",
        "1. **Predict Probabilities:**\n",
        "   - Use the trained model to predict probabilities for each class for the test data (`X_test_pad`).\n",
        "\n",
        "2. **Convert Probabilities to Class Labels:**\n",
        "   - Convert the predicted probabilities into class labels by selecting the class with the highest probability.\n",
        "\n",
        "3. **Compute Confusion Matrix:**\n",
        "   - Generate the confusion matrix using the true class labels (`y_test_categorical`) and the predicted class labels (`y_pred`).\n",
        "\n",
        "4. **Print Confusion Matrix:**\n",
        "   - Print the confusion matrix to visualize the performance of the classification model.\n",
        "\n",
        "5. **Calculate Precision, Recall, and F1-score:**\n",
        "   - Compute precision, recall, and F1-score using the `classification_report` function.\n",
        "\n",
        "### Parameters:\n",
        "- `X_test_pad`: Test data with padded sequences (features).\n",
        "- `y_test_categorical`: True labels of the test data in one-hot encoded format.\n",
        "- `model`: Trained classification model.\n",
        "\n",
        "### Returns:\n",
        "- `conf_matrix`: Confusion matrix showing the number of true positive, true negative, false positive, and false negative predictions for each class.\n",
        "- `report`: Classification report containing precision, recall, and F1-score for each class, along with the overall accuracy, weighted average precision, recall, and F1-score.\n",
        "\n"
      ],
      "metadata": {
        "id": "u0dTz1a22EBR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6UiuYjJN0NY",
        "outputId": "b37171f3-f17b-4645-b01c-e90cdb184c76"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "924/924 [==============================] - 24s 25ms/step\n",
            "Confusion Matrix:\n",
            "[[9649  315  457  191  872]\n",
            " [ 243 4602  278  139  316]\n",
            " [ 530  370 5535  289  544]\n",
            " [ 190   96  181 1659  157]\n",
            " [ 336  113  194   89 2200]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.84      0.86     11484\n",
            "           1       0.84      0.83      0.83      5578\n",
            "           2       0.83      0.76      0.80      7268\n",
            "           3       0.70      0.73      0.71      2283\n",
            "           4       0.54      0.75      0.63      2932\n",
            "\n",
            "    accuracy                           0.80     29545\n",
            "   macro avg       0.76      0.78      0.77     29545\n",
            "weighted avg       0.81      0.80      0.80     29545\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "# Predict probabilities for each class for the test data\n",
        "y_pred_prob = model.predict(X_test_pad)\n",
        "\n",
        "# Convert probabilities to class labels\n",
        "y_pred = np.argmax(y_pred_prob, axis=1)\n",
        "\n",
        "# Compute confusion matrix\n",
        "conf_matrix = confusion_matrix(np.argmax(y_test_categorical, axis=1), y_pred)\n",
        "\n",
        "# Print confusion matrix\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "# Calculate precision, recall, and F1-score\n",
        "report = classification_report(np.argmax(y_test_categorical, axis=1), y_pred)\n",
        "print(\"Classification Report:\")\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fUjaGO2KN2cH",
        "outputId": "6bdcdd1d-ee5e-4cf0-acd3-b6711d0a6203"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "model.save(\"lstm_model_2.h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# compare the confusion matrices for each model:\n",
        "\n",
        "### Model Comparison: Confusion Matrix\n",
        "\n",
        "| Model | Precision (EG) | Recall (EG) | F1-Score (EG) | Precision (LB) | Recall (LB) | F1-Score (LB) | Precision (LY) | Recall (LY) | F1-Score (LY) | Precision (MA) | Recall (MA) | F1-Score (MA) | Precision (SD) | Recall (SD) | F1-Score (SD) | Accuracy |\n",
        "|-------|----------------|-------------|----------------|----------------|-------------|----------------|----------------|-------------|----------------|----------------|-------------|----------------|----------------|-------------|----------------|----------|\n",
        "| Logistic Regression with TF-IDF Vectorization | 0.89 | 0.82 | 0.85 | 0.82 | 0.83 | 0.83 | 0.78 | 0.80 | 0.79 | 0.69 | 0.74 | 0.71 | 0.63 | 0.71 | 0.67 | 0.80 |\n",
        "| Logistic Regression with CountVectorizer | 0.88 | 0.83 | 0.85 | 0.81 | 0.84 | 0.82 | 0.78 | 0.80 | 0.79 | 0.70 | 0.71 | 0.71 | 0.64 | 0.68 | 0.66 | 0.80 |\n",
        "| Multinomial Naive Bayes with TF-IDF Vectorization | 0.88 | 0.83 | 0.85 | 0.86 | 0.83 | 0.84 | 0.89 | 0.70 | 0.79 | 0.50 | 0.79 | 0.61 | 0.53 | 0.72 | 0.61 | 0.78 |\n",
        "| Multinomial Naive Bayes with CountVectorizer | 0.86 | 0.90 | 0.88 | 0.86 | 0.85 | 0.86 | 0.85 | 0.78 | 0.81 | 0.70 | 0.72 | 0.71 | 0.66 | 0.67 | 0.67 | 0.82 |\n",
        "| Deep Learning Model | 0.88 | 0.84 | 0.86 | 0.84 | 0.83 | 0.83 | 0.83 | 0.76 | 0.80 | 0.70 | 0.73 | 0.71 | 0.54 | 0.75 | 0.63 | 0.80 |\n",
        "\n",
        "### Interpretation:\n",
        "- The table provides precision, recall, and F1-score for each class (dialect) for all models.\n",
        "- The accuracy of each model is also included in the last column.\n",
        "- Based on these metrics, you can compare the performance of different models in classifying Arabic dialects.\n",
        "\n",
        "This comparison allows for a quick evaluation of each model's performance across different evaluation metrics."
      ],
      "metadata": {
        "id": "rfGpg1024IhR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# interpret the results and determine the best model, let's analyze the metrics provided in the table:\n",
        "\n",
        "1. **Precision, Recall, and F1-Score:**\n",
        "   - **Precision:** It measures the accuracy of the positive predictions. A high precision indicates a low false positive rate, meaning that the model is good at predicting positive cases correctly.\n",
        "   - **Recall:** It measures the ability of the model to capture all positive instances. A high recall indicates a low false negative rate, meaning that the model is good at identifying all positive cases.\n",
        "   - **F1-Score:** It is the harmonic mean of precision and recall. It provides a balance between precision and recall.\n",
        "\n",
        "2. **Accuracy:**\n",
        "   - It measures the overall correctness of the model's predictions across all classes.\n",
        "\n",
        "Based on the provided results:\n",
        "- **Logistic Regression with CountVectorizer** and **Multinomial Naive Bayes with CountVectorizer** achieve similar performance across all metrics, with slightly higher accuracy compared to the other models.\n",
        "- **Deep Learning Model** performs well in terms of accuracy but has slightly lower precision, recall, and F1-score compared to the other models for certain classes.\n",
        "- **Logistic Regression with TF-IDF Vectorization** shows good performance but may have slightly lower accuracy and F1-scores compared to the CountVectorizer-based models.\n",
        "\n",
        "**Choosing the Best Model:**\n",
        "- The choice of the best model depends on the specific requirements and priorities of the task. If overall accuracy is the primary concern, the CountVectorizer-based models or the Deep Learning Model may be preferred.\n",
        "- If balanced performance across precision, recall, and F1-score is crucial, the Logistic Regression or Naive Bayes models with CountVectorizer might be preferable.\n",
        "- It's essential to consider factors such as computational complexity, interpretability, and deployment constraints when selecting the final model."
      ],
      "metadata": {
        "id": "33Hkp77V4get"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}